{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iir/work/ben/NCKU/IIR/SemEval2025_Task9\n",
      "/home/iir/work/ben/NCKU/IIR/SemEval2025_Task9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd /home/iir/work/ben/NCKU/IIR/SemEval2025_Task9\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/augllms/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch.nn.functional as F\n",
    "from src.MyDataset import MyDataset\n",
    "from src.BertSentimentClassifier import BertSentimentClassifier\n",
    "from src.utils import *\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download testing data (conception phase, unlabeled):\n",
    "# !wget https://codalab.lisn.upsaclay.fr/my/datasets/download/26c12bc0-3878-4edf-8b4a-9682763c0b7e\n",
    "# !unzip -o 26c12bc0-3878-4edf-8b4a-9682763c0b7e\n",
    "# !rm 26c12bc0-3878-4edf-8b4a-9682763c0b7e\n",
    "\n",
    "# load test data:\n",
    "test_df = pd.read_csv('data/incidents_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_bert = \"microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract\"\n",
    "tokenizer = BertTokenizer.from_pretrained(name_bert) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder() \n",
    "label_encoder.classes_ = np.load('models/ST1/hazard_category/hazard_category_label_encoder.npy', allow_pickle=True)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['allergens', 'biological', 'chemical',\n",
       "       'food additives and flavourings', 'foreign bodies', 'fraud',\n",
       "       'migration', 'organoleptic aspects', 'other hazard',\n",
       "       'packaging defect'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_model(weight_path, bert_model_name, num_classes):\n",
    "    model_predict = BertSentimentClassifier(bert_model_name, num_classes)\n",
    "    model_predict.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    return model_predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "test_df = MyDataset(test_df, tokenizer, max_len, inference=True)\n",
    "test_loader = DataLoader(test_df, batch_size=1, shuffle=True ) \n",
    "weight_path = \"models/ST1/hazard_category/best_st1_hazard_category_large_200.pt\"\n",
    "model_predict = load_bert_model(weight_path, name_bert, num_classes=len(label_encoder.classes_)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 565/565 [00:08<00:00, 68.39it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_list = []\n",
    "predicted_probs_list = []\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    # move the inputs to the device\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "    # Get predicted labels and probabilities\n",
    "    # disable gradient computation\n",
    " \n",
    "    outputs = model_predict(input_ids, attention_mask).to(device)\n",
    "    predicted_labels = torch.argmax(outputs, dim=1).tolist()[0]\n",
    "    predicted_probs = torch.nn.functional.softmax(outputs, dim=1)[0].tolist() \n",
    "    predicted_labels_list.append(predicted_labels)\n",
    "    predicted_probs_list.append(predicted_probs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 565/565 [00:08<00:00, 69.59it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "predicted_probs = []\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    # move the inputs to the device\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "    # Get predicted labels and probabilities\n",
    "    # disable gradient computation\n",
    " \n",
    "    outputs = model_predict(input_ids, attention_mask).to(device)\n",
    "\n",
    "    predicted_labels.append(label_encoder.inverse_transform(torch.argmax(outputs, dim=1).tolist())) \n",
    "    predicted_probs.append(torch.nn.functional.softmax(outputs, dim=1)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "\n",
    "for column in ['hazard-category', 'product-category', 'hazard', 'product']:\n",
    "  predictions[column] = predict(test_df.title.to_list(), f\"bert_{column.replace('-', '_')}\")\n",
    "\n",
    "predictions.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augllms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
